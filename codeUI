# Code giao di·ªán v·ªõi mapping ƒë√£ s·ª≠a l·ªói
import gradio as gr
import tensorflow as tf
from tensorflow.keras.models import load_model
import numpy as np
import json
import os
import glob
from PIL import Image

# C√†i ƒë·∫∑t gradio n·∫øu ch∆∞a c√≥
!pip install gradio

class FlowerClassificationFixed:
    def __init__(self):
        self.model = None
        self.class_names = []
        self.img_size = (160, 160)
        self.model_path = None
        
    def find_latest_model(self):
        """T√¨m model m·ªõi nh·∫•t"""
        possible_paths = [
            "/content/drive/MyDrive/flowers5_runs",
            "/content",
            "/content/drive/MyDrive"
        ]
        
        model_files = []
        for base_path in possible_paths:
            if os.path.exists(base_path):
                keras_files = glob.glob(os.path.join(base_path, "**", "*.keras"), recursive=True)
                h5_files = glob.glob(os.path.join(base_path, "**", "*.h5"), recursive=True)
                model_files.extend(keras_files + h5_files)
        
        if not model_files:
            return None, None
        
        model_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        latest_model = model_files[0]
        model_dir = os.path.dirname(latest_model)
        meta_file = os.path.join(model_dir, "meta.json")
        
        return latest_model, meta_file if os.path.exists(meta_file) else None
    
    def load_model_and_setup(self):
        """Load model v√† setup"""
        print("üîç T√¨m ki·∫øm model ƒë√£ train...")
        
        model_path, meta_path = self.find_latest_model()
        if not model_path:
            raise FileNotFoundError("‚ùå Kh√¥ng t√¨m th·∫•y model. H√£y ch·∫°y code training tr∆∞·ªõc.")
        
        print(f"üì¶ ƒê√£ t√¨m th·∫•y model: {model_path}")
        
        try:
            print("‚è≥ ƒêang load model...")
            self.model = load_model(model_path)
            print("‚úÖ Model ƒë√£ load th√†nh c√¥ng!")
            
            self.model_path = model_path
            self.class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']
            
            print(f"üìä Th√¥ng tin model:")
            print(f"   Input shape: {self.model.input_shape}")
            print(f"   Output shape: {self.model.output_shape}")
            print(f"   Classes: {self.class_names}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói khi load model: {e}")
            return False
    
    def preprocess_image(self, image):
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh theo format c·ªßa model"""
        if isinstance(image, Image.Image):
            img_array = np.array(image)
        else:
            img_array = image
        
        # Resize v·ªÅ k√≠ch th∆∞·ªõc model mong ƒë·ª£i
        img_resized = tf.image.resize(img_array, self.img_size)
        
        # Preprocessing theo MobileNetV2
        img_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(img_resized)
        
        # Th√™m batch dimension
        img_batch = tf.expand_dims(img_preprocessed, 0)
        
        return img_batch
    
    def predict_flower(self, image):
        if self.model is None:
            return "‚ùå Model ch∆∞a ƒë∆∞·ª£c load. Vui l√≤ng ch·∫°y l·∫°i setup."
        
        try:
            # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
            processed_image = self.preprocess_image(image)
            
            # D·ª± ƒëo√°n
            predictions = self.model.predict(processed_image, verbose=0)
            raw_predictions = predictions[0]
            

            
            corrected_results = {}

            corrected_results['daisy'] = float(raw_predictions[1])     
            corrected_results['dandelion'] = float(raw_predictions[0]) 
            corrected_results['roses'] = float(raw_predictions[4])     
            corrected_results['tulips'] = float(raw_predictions[2])     
            corrected_results['sunflowers'] = float(raw_predictions[3]) 
            
            print(f"Raw predictions: {[f'{x:.3f}' for x in raw_predictions]}")
            print(f"Corrected mapping: {corrected_results}")
            
            return corrected_results
            
        except Exception as e:
            return f"‚ùå L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {str(e)}"
    
    def create_interface(self):
        """T·∫°o giao di·ªán Gradio"""
        
        custom_css = """
        .gradio-container {
            max-width: 900px;
            margin: auto;
            padding: 20px;
            font-family: 'Segoe UI', sans-serif;
        }
        .title {
            text-align: center;
            color: #2d3748;
            font-weight: bold;
        }
        """
        
        model_info = f"""
        ### ü§ñ
        """
        
        interface = gr.Interface(
            fn=self.predict_flower,
            inputs=[
                gr.Image(
                    type="pil", 
                    label="üì∏ Upload ·∫£nh hoa ƒë·ªÉ nh·∫≠n di·ªán",
                    height=400
                )
            ],
            outputs=[
                gr.Label(
                    num_top_classes=5, 
                    label="üéØ K·∫øt qu·∫£ nh·∫≠n di·ªán",
                    show_label=True
                )
            ],
            title="üå∏ Nh·∫≠n Di·ªán Hoa",
            description="""
            """,
            article=model_info,
            theme=gr.themes.Soft(),
            css=custom_css
        )
        
        return interface

# H√†m ch√≠nh ƒë·ªÉ ch·∫°y giao di·ªán
def main():
    print("üöÄ Kh·ªüi t·∫°o giao di·ªán nh·∫≠n di·ªán hoa...")
    print("="*60)
    
    try:
        flower_interface = FlowerClassificationFixed()
        
        if not flower_interface.load_model_and_setup():
            print("‚ùå Kh√¥ng th·ªÉ load model")
            return
        
        print("\n" + "="*60)
        print("üé® T·∫°o giao di·ªán web...")
        
        demo = flower_interface.create_interface()
        
        print("üåê Kh·ªüi ƒë·ªông giao di·ªán...")
        demo.launch(
            share=True,
            debug=True,
            inbrowser=True,
            server_name="0.0.0.0",
            server_port=7862  # Port kh√°c ƒë·ªÉ tr√°nh conflict
        )
        
        print("\n" + "="*60)
        print("üéâ Giao di·ªán kh·ªüi ƒë·ªông th√†nh c√¥ng!")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")

# Ch·∫°y giao di·ªán
if __name__ == "__main__":
    main()
